# Как архивировать?

## Выгрузка сайта

Самый простой способ скачать сайт программой wget, которая присутсвует почти
в любом дистрибутиве Linux:

```sh
wget --mirror -p --convert-links -P . xyz.com
```

Объяснение:

1. `--mirror` - скачать сайт целиком
2. `-p` - загрузить все файлы необходимые для корректного отображения страницы
3. `--convert-links` - заменить ссылки на странице, для возможности локальной навигации
3. `-P .` - путь сохранения, в данном случае в текущую директорию (`./xyz.com`)

## Скачка по набору url

Последняя часть (имя файла) в ссылках должна быть уникально, иначе последующие файлы перезапишут предыдущие.

Сохранить все url в файл (каждая ссылка с новой строки).

Перейти в директорию, в которую всё будет скачиваться. Выполнить комманду:

```sh
wget -i файл_с_url
```